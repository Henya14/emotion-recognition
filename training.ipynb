{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f257bef",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fd4b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5893f8",
   "metadata": {},
   "source": [
    "# Declaring constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e183c983",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "MAX_SEQUENCE_LEN = 32\n",
    "NUM_OF_CHANNELS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baf3bea",
   "metadata": {},
   "source": [
    "# Building the model\n",
    "Code from https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/vision/ipynb/video_classification.ipynb#scrollTo=8PXw88Y1_s2x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7122bc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionRecognitionModel(tf.keras.Model):\n",
    "    def __init__(self, classes, *args, **kwargs):\n",
    "        super(EmotionRecognitionModel, self).__init__(*args, **kwargs)\n",
    "        self.feature_extractor = hub.KerasLayer(\"https://tfhub.dev/shoaib6174/swin_small_patch244_window877_kinetics400_1k/1\")\n",
    "        self.feature_extractor.trainable = False\n",
    "\n",
    "        #self.Conv3d = layers.Conv3D(filters=16, kernel_size=3,activation=\"relu\")\n",
    "        #self.MaxPool3d = layers.MaxPool3D()\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.dense1 = layers.Dense(units=16, activation=\"relu\")\n",
    "        self.dropout = layers.Dropout(0.4)\n",
    "        self.dense2 = layers.Dense(8, activation=\"relu\")\n",
    "        self.dense3 = layers.Dense(len(classes), activation=\"softmax\")\n",
    "    \n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.feature_extractor(inputs)\n",
    "        #x = self.Conv3d(x)\n",
    "        #x = self.MaxPool3d(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8196c15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(train_df[\"emotion\"].values)\n",
    "transformer_model = EmotionRecognitionModel(classes)\n",
    "\n",
    "LR = 1e-3\n",
    "transformer_model.compile(optimizer=keras.optimizers.Adam(learning_rate=LR),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[\"accuracy\"])\n",
    "transformer_model.build(input_shape=(None, NUM_OF_CHANNELS, MAX_SEQUENCE_LEN, IMG_SIZE, IMG_SIZE))\n",
    "transformer_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940472f8",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3fce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df = tf.data.Dataset.load(os.path.join(\"data\", \"prepared_train_dataset\")).map(lambda vid, label: (tf.cast((vid / 255.0), tf.float32), label))\n",
    "v_df = tf.data.Dataset.load(os.path.join(\"data\", \"prepared_validation_dataset\")).map(lambda vid, label: (tf.cast((vid / 255.0), tf.float32), label))\n",
    "\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "filepath = \"/tmp/emotion_classifier\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, save_weights_only=True, save_best_only=True, verbose=1)\n",
    "\n",
    "EPOCH_NUM = 10\n",
    "transformer_model.fit(x=t_df.shuffle(200).batch(16), epochs=EPOCH_NUM, validation_data=v_df.batch(16), callbacks=[checkpoint, tensorboard_callback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
